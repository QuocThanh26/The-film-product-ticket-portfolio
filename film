Skip to main content
Project.ipynb
Project.ipynb_
Last edited on Dec 3, 2024
Table of contents
1. Load Data
2. Data Cleaning
2.1 data type, NULL values, Duplicate values
2.2 Join Table
2.3 View all values of each columns
3.Analyze
3.1 Customer portrait
Age and gender distribution
Age generation distribution
3.2 Time Series data - when did customers buy tickets?
Trend by month
Trend by week days
Trend by hour
3.3 Factors related to the customer's purchasing process
Payment platform
OS Version
Payment method
Promotion
Which movies they watched?
3.4 Customer value dimension
Frequency & anomaly behavior
Masive Promotion
3.5 Customer Retention - Cohort Analysis
Compare: Retention of promotion customers & organic customers
3.6 Payment success rate
Overview
Error trend
SR=0% WHY and HOW ?
1. Load Data

[ ]
# Import một số thư viện quan trọng
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
pd.set_option('display.max_colwidth',None) # truy xuất hết nội dung trong cột
pd.set_option('display.max_columns',None) # truy xuất hết các cột trong dataframe

[ ]
# Connect with Google Drive
from google.colab import drive
drive.mount('/content/drive')
Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).

[ ]
df_customer = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Project/Data/movie_ticket_data/movie_ticket_data/customer.csv')
df_campaign = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Project/Data/movie_ticket_data/movie_ticket_data/campaign.csv')
df_device = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Project/Data/movie_ticket_data/movie_ticket_data/device_detail.csv')
df_status = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Project/Data/movie_ticket_data/movie_ticket
2. Data Cleaning
2.1 data type, NULL values, Duplicate values

[ ]
# Bảng Customer
df_customer.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 131400 entries, 0 to 131399
Data columns (total 3 columns):
 #   Column       Non-Null Count   Dtype 
---  ------       --------------   ----- 
 0   customer_id  131400 non-null  int64 
 1   usergender   131400 non-null  object
 2   dob          131400 non-null  object
dtypes: int64(1), object(2)
memory usage: 3.0+ MB

[ ]
df_customer.head(2)


[ ]
# chuyển đổi data type dob từ object thành datetime
from datetime import datetime # sử dụng module datetime trong Python có sẵn trong Python
df_customer['dob'] = pd.to_datetime(df_customer['dob'])

[ ]
df_customer.info() # => data type xong, Null values df_customer không có nên kiểm tra đến duplicate values
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 131400 entries, 0 to 131399
Data columns (total 3 columns):
 #   Column       Non-Null Count   Dtype         
---  ------       --------------   -----         
 0   customer_id  131400 non-null  int64         
 1   usergender   131400 non-null  object        
 2   dob          131400 non-null  datetime64[ns]
dtypes: datetime64[ns](1), int64(1), object(1)
memory usage: 3.0+ MB

[ ]
df_customer['customer_id'].nunique() # => bảng này không bị trùng xong bảng customer
131400

[ ]
# Bảng campaign
df_campaign.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 216 entries, 0 to 215
Data columns (total 2 columns):
 #   Column         Non-Null Count  Dtype 
---  ------         --------------  ----- 
 0   campaign_id    216 non-null    int64 
 1   campaign_type  216 non-null    object
dtypes: int64(1), object(1)
memory usage: 3.5+ KB

[ ]
df_campaign.head(2)


[ ]
df_campaign['campaign_id'].nunique()
216

[ ]
# Bảng device
df_device.info()
# => ta thấy bảng device của ta có 139902 dòng dữ liệu, column device_number có 139901 còn model có 132763 data
# => như vậy bảng device của ta có một số lượng bị Null
# => Khi data bị Null ta phải kiểm tra Null bao nhiêu % trong tổng số dữ liệu của column trước khi xử lý: xóa đi or thay thế nó
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 139902 entries, 0 to 139901
Data columns (total 3 columns):
 #   Column         Non-Null Count   Dtype 
---  ------         --------------   ----- 
 0   device_number  139901 non-null  object
 1   model          132763 non-null  object
 2   platform       139902 non-null  object
dtypes: object(3)
memory usage: 3.2+ MB

[ ]
# tạo function calculate số dòng Null và tỷ lệ % của từng column
def calc_null_rate(df):
    newdf = df.isnull().sum().to_frame('null_count')
    newdf[['null_rate']] = newdf[['null_count']] / len(df)
    return newdf.sort_values(by=['null_rate'], ascending=False)


[ ]
calc_null_rate(df_device)
# => model bị null 7139 dữ liệu khoảng 5% nên ta thay thế số lượng bị null này thành unknown vẫn giữ để có thể đo lường, đánh giá
# => còn device_number null 1 dữ liệu ta xóa vì nó không ảnh hưởng


[ ]
# thay thế Null trong model thành 'unknown' ,NA: Not Available
df_device = df_device.fillna({'model' : 'unknown'})
# xóa giá trị Null trong cột device_number
df_device = df_device[df_device['device_number'].notna()]

[ ]
calc_null_rate(df_device)


[ ]
df_device.info()
<class 'pandas.core.frame.DataFrame'>
Index: 139901 entries, 0 to 139900
Data columns (total 3 columns):
 #   Column         Non-Null Count   Dtype 
---  ------         --------------   ----- 
 0   device_number  139901 non-null  object
 1   model          139901 non-null  object
 2   platform       139901 non-null  object
dtypes: object(3)
memory usage: 4.3+ MB

[ ]
# bảng status
df_status.head(10)


[ ]
# bảng ticket
df_ticket.head(2)


[ ]
df_ticket.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 154827 entries, 0 to 154826
Data columns (total 12 columns):
 #   Column          Non-Null Count   Dtype  
---  ------          --------------   -----  
 0   ticket_id       154827 non-null  object 
 1   customer_id     154827 non-null  int64  
 2   paying_method   154827 non-null  object 
 3   theater_name    154827 non-null  float64
 4   device_number   154827 non-null  object 
 5   original_price  154827 non-null  float64
 6   discount_value  154827 non-null  float64
 7   final_price     154827 non-null  float64
 8   time            154827 non-null  object 
 9   status_id       154827 non-null  int64  
 10  campaign_id     154827 non-null  int64  
 11  movie_name      154827 non-null  object 
dtypes: float64(4), int64(3), object(5)
memory usage: 14.2+ MB

[ ]
# thay đổi data type của cột time
df_ticket['time'] = pd.to_datetime(df_ticket['time'])

[ ]
df_ticket.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 154827 entries, 0 to 154826
Data columns (total 12 columns):
 #   Column          Non-Null Count   Dtype         
---  ------          --------------   -----         
 0   ticket_id       154827 non-null  object        
 1   customer_id     154827 non-null  int64         
 2   paying_method   154827 non-null  object        
 3   theater_name    154827 non-null  float64       
 4   device_number   154827 non-null  object        
 5   original_price  154827 non-null  float64       
 6   discount_value  154827 non-null  float64       
 7   final_price     154827 non-null  float64       
 8   time            154827 non-null  datetime64[ns]
 9   status_id       154827 non-null  int64         
 10  campaign_id     154827 non-null  int64         
 11  movie_name      154827 non-null  object        
dtypes: datetime64[ns](1), float64(4), int64(3), object(4)
memory usage: 14.2+ MB

[ ]
calc_null_rate(df_ticket)


[ ]
df_ticket['ticket_id'].nunique()
154725

[ ]
154827 - 154725 #mình có 102 dữ liệu trùng
# => kiểm tra dữ liệu duplicate
102

[ ]
df_dup = df_ticket[df_ticket.duplicated(keep = False)]
# keep là giữ nguyên bản sao
#keep : {'first', 'last', False}, mặc định là first
  ##first: Đánh dấu bản sao là True trừ lần xuất hiện đầu tiên. (nghĩa là truy xuất ra)
  ##last: Đánh dấu bản sao là True trừ lần xuất hiện cuối cùng.
  ##False: Đánh dấu tất cả bản sao là True. (nghĩa là truy xuất tất cả các dòng bị trùng)

[ ]
df_dup.head(10)
#=> kiểm tra các dòng trùng thực sự


[ ]
df_ticket.drop_duplicates(inplace= True) #thay đổi lưu lại trên dataframe này còn false là tạo 1 dataframe mới

[ ]
df_ticket['ticket_id'].nunique()
154725

[ ]
df_ticket.info() #=> kiểm tra lại 154725 đủ dữ liệu
<class 'pandas.core.frame.DataFrame'>
Index: 154725 entries, 0 to 154826
Data columns (total 12 columns):
 #   Column          Non-Null Count   Dtype         
---  ------          --------------   -----         
 0   ticket_id       154725 non-null  object        
 1   customer_id     154725 non-null  int64         
 2   paying_method   154725 non-null  object        
 3   theater_name    154725 non-null  float64       
 4   device_number   154725 non-null  object        
 5   original_price  154725 non-null  float64       
 6   discount_value  154725 non-null  float64       
 7   final_price     154725 non-null  float64       
 8   time            154725 non-null  datetime64[ns]
 9   status_id       154725 non-null  int64         
 10  campaign_id     154725 non-null  int64         
 11  movie_name      154725 non-null  object        
dtypes: datetime64[ns](1), float64(4), int64(3), object(4)
memory usage: 15.3+ MB

[ ]
#Sau khi kiểm tra data type, NULL values, duplicate values xong ta kiểm tra tới outliers, dữ liệu có sai format chính tả
2.2 Join Table

[ ]
# Xuất phát từ bảng ticket join các bảng Dimension còn lại
df_join_customer = pd.merge(df_ticket, df_customer, how = 'left', on = 'customer_id')
df_join_campaign = pd.merge(df_join_customer,df_campaign, how = 'left', on = 'campaign_id')
df_join_status = pd.merge(df_join_campaign,df_status, how = 'left', on = 'status_id')
df_join_all = pd.merge(df_join_status,df_device,how = 'left', on = 'device_number' )

[ ]
df_join_all.count()


[ ]
df_join_all.head(2)


[ ]
#Sau khi join hết rồi kiểm tra lại nó có bị null nào không
calc_null_rate(df_join_all)
# => error_group null vì khi giao dịch thành công cột error_group là NaN nên không tìm thấy dữ liệu
# => campaign_type null vì những đơn hàng nó không sử dụng chiến dịch khuyến mãi
## => 2 column này có giá trị null hợp lý
# platform và model trong vài trường hợp không tìm thấy dữ liệu

# => trong trường hợp này ta thay thế các kết quả null thành 'unknown'



[ ]
df_join_all = df_join_all.fillna('unknown')

[ ]
calc_null_rate(df_join_all)

2.3 View all values of each columns

[ ]
df_join_all.nunique().sort_values(ascending = False)


[ ]
##kiểm tra lỗi chính tả có trùng hay không
specific_cols = ['movie_name','description','paying_method','campaign_type','usergender','platform', 'error_group']
for col in specific_cols:
    print(col + ' : ', np.sort(df_join_all[col].unique().astype(str)))
    print('\r') # \r (Carriage Return) - là di chuyển con trỏ về đầu dòng (xuống dòng)
    print('--------------------------')
    print('\r')
movie_name :  ['13rd Sister' '13rd Sister: Three Deadly Days' '1990' '2037'
 '30 Chua Phai Tet' '47 Meters Down: Uncaged' 'A Chamada Da Selva'
 'A Diamond In The Rough' 'Accidentally Dad' 'Aladdin' 'Alienoid'
 'Alita: Battle Angel' 'Ambulance' 'Anchor' 'Angel Has Fallen' 'Anna'
 'Annabelle Comes Home' 'Aquaman' 'Around The World In 80 Days'
 'Autumn Promise' 'Avatar' 'Avatar: The Way Of Water' 'Avengers: Endgame'
 'Bad Boys For Life' 'Batman' 'Beast' 'Birds Of Prey' 'Black Adam'
 'Black Panther 2: Wakanda Forever' 'Black Panther: Wakanda Forever'
 'Blood Karma' 'Blood Moon Party' 'Bloodshot' 'Broker' 'Bullet Train'
 'Bumblebee' 'Bắc Kim Thang' 'Camellia Sisters' 'Captain Marvel'
 "Charlie's Angels" 'Cherry Magic The Movie Thirty Years'
 'Chickenhare And The Hamster Of Darkness' 'Chuyện Ma Đô Thị' 'Collectors'
 'Concessions' 'Confidential Assignment 2: International' 'Cracked'
 'Crawl' 'Crazy Romance' "Dad I'm Sorry" 'Daddy Issues' 'Daeng'
 'Dark Figure Of Crime' 'Dc League Of Super-Pets' 'Dear Devil Brother'
 'Death On The Nile' 'Decibel' 'Decision To Leave'
 'Demon Slayer: Kimetsu No Yaiba'
 'Detective Conan: The Bride Of Halloween'
 'Detective Conan: The Fist Of Blue Sapphire'
 'Detective Conan: The Scarlet Bullet' 'Doctor Sleep'
 'Doctor Strange In The Multiverse Of Madness' 'Dolittle'
 "Doraemon: Nobita's Chronicle Of The Moon"
 "Doraemon: Nobita's Little Star Wars 2021"
 "Doraemon: Nobita's New Dinosaur" 'Dragon Ball Super: Super Hero'
 'Dreamy Eyes' 'Em La Cua Em' 'Emergency Declaration' 'Encanto'
 'Escape Room' 'Eternals' 'Everest' 'Everything Everywhere All At Once'
 'Exit' 'Extreme Job' 'Extremely Easy Job' 'Face Off: 48h'
 'Fantastic Beasts: Secrets Of Dumbledore'
 'Fantastic Beasts: The Secrets Of Dumbledore'
 'Fast & Furious Presents: Hobbs & Shaw' 'Fast Film' 'Friend Zone'
 'Frozen 2' 'Frozen Ii' 'Furie' 'Furies' 'Gemini Man' 'Girl From The Past'
 'Glass' 'Glorious Ashes' 'Godzilla Vs. Kong'
 'Godzilla: King Of The Monsters' 'Goodbye Mother' 'Greenland'
 'Harry Potter' 'Harry Potter And The Chamber Of Secrets'
 'Harry Potter And The Deathly Hallows'
 'Harry Potter And The Goblet Of Fire'
 "Harry Potter And The Philosopher's Stone"
 'Harry Potter And The Prisoner Of Azkaban' 'Hellboy' 'Hitman: Agent Jun'
 'Honest Thief' 'House Of Gucci' 'How To Train Your Dragon'
 'Inseparable Bros' 'It Chapter Two' 'Ivanna' 'Jailangkung: Sandekala'
 'John Wick 3: Parabellum' 'John Wick: Chapter 3 – Parabellum' 'Joker'
 'Jujutsu Kaisen 0' 'Jumanji' 'Jun-45' 'Jurassic World Dominion'
 'Key Of Life Vietnam' 'Kisaragi Station' 'Knives Out' 'Kumanthong'
 'Lat Mat 4: Nha Co Khach' 'Lightyear' 'Lost In Mekong Delta'
 'Love Battle' 'Love Destiny' 'Love Destiny: The Movie'
 'Lyle Lyle Crocodile' 'Maika' 'Maleficent' 'Maleficent: Mistress Of Evil'
 'Men Gai Mien Tay' 'Men In Black: International'
 'Minions: The Rise Of Gru' 'Miss Gangster' 'Moonfall' 'Morbius'
 'Mortal Kombat' 'Muoi: The Curse Returns' 'My Father Is A Playboy'
 'My Female Partner' 'My Girl' 'Naked Truth'
 'Nct Dream The Movie : In A Dream' 'Ne Zha' 'Ngoi Nha Buom Buom'
 'No Time To Die' 'Nope' 'Once Upon A Time... In Hollywood'
 'One Piece Film: Red' 'One Piece: Stampede' 'P Storm' 'Parasite' 'Pawn'
 'Paws Of Fury: The Legend Of Hank' 'Peninsula'
 'Pháp Sư Mù: Ai Chết Giơ Tay' 'Pil' 'Playing With Fire'
 'Pokémon Detective Pikachu' 'Pokémon: Detective Pikachu'
 'Prey For The Devil' 'Puss In Boots: The Last Wish'
 'Raya And The Last Dragon' 'Rom' 'Romang' "Satan's Slaves 2"
 'Scary Stories To Tell In The Dark' 'Secret Zoo' 'Semantic Error'
 'Seo Bok' 'Shang Chi' 'Shark Bait' 'Shazam!' 'Shutter Island' 'Sing 2'
 'Sister Sister' 'Smile' 'Soul' 'Spider' 'Spider-Man Far From Home'
 'Spider-Man: No Way Home' 'Spies In Disguise'
 'Star Wars: The Rise Of Skywalker' 'Starium' 'Superstar Teacher'
 'Tazza: One Eyed Jack' 'Tenet' 'Terminator: Dark Fate'
 'The Addams Family' 'The Ancestral' 'The Angry Birds Movie 2'
 'The Bad Guys' 'The Bad Guys: Reign Of Chaos' 'The Batman'
 'The Black Phone' 'The Brilliant Darkness!' 'The Con-Heartist'
 'The Croods: A New Age' 'The Curse Of La Llorona' 'The Divine Fury'
 'The Drama Queen' 'The Eyes' 'The Father'
 'The Ghoul: Horror At The Howling Field' 'The Golden Holiday'
 'The Guardian' 'The Hustle' 'The Instrument Of Murder'
 'The Invisible Man' 'The Invitation' 'The Lion King'
 'The Lord Of The Rings' 'The Lost City' 'The Medium' 'The Menu'
 'The New King Of Comedy' 'The Nightmares' 'The Perfect Wedding'
 "The Queen's Corgi" 'The Royal Bride' 'The Secret Life Of Pets 2'
 'The Third Wife' 'The White Storm 2: Drug Lords'
 'The Witch: Part 2. The Other One' 'The Witcher'
 'This House Is Not For Sal' 'Thor: Love And Thunder' 'Ticket To Paradise'
 'Tom' 'Top Gun: Maverick' 'Toy Story 4' 'Truyên Ngan' 'Trạng Quỳnh'
 'Trạng Tí' 'Turning Red' 'Underwater' 'Us' 'Venom: Let There Be Carnage'
 'Vietnamese Horror Story' 'Violent Night' 'Weathering With You'
 'Where The Crawdads Sing' 'Win My Baby Back' 'Wonder Woman 1984'
 'Wrath Of Man' 'X' 'You And Trinh' 'Zhu Xian' 'Zombieland: Double Tap']

--------------------------

description :  ['Insufficient funds in customer account. Please add more funds and try the transaction again.'
 'Need verify your account to continue' 'No response from your bank'
 'Order successful'
 'Password locked due to multiple incorrect attempts. Choose Forgot Password to unlock.'
 'Payment failed from bank' 'Payment overdue'
 'Transaction temporarily limited']

--------------------------

paying_method :  ['bank account' 'credit card' 'debit card' 'money in app' 'other']

--------------------------

campaign_type :  ['direct discount' 'reward point' 'unknown' 'voucher']

--------------------------

usergender :  ['Female' 'Male' 'Not verify']

--------------------------

platform :  ['mobile' 'unknown' 'website']

--------------------------

error_group :  ['customer' 'external' 'internal' 'unknown']

--------------------------

3.Analyze
3.1 Customer portrait
Age and gender distribution

[ ]
df_join_all.head(2)


[ ]
#tính số tuổi
#trong python không có hàm year nên ta quy về ngày để tính
current_date = datetime.now()
df_join_all['age_days'] = (current_date - df_join_all['dob']).dt.days #.dt.days nghĩa dt là datetime chuyển sang theo đơn vị ngày trong datetime
df_join_all['age'] = df_join_all['age_days'] / 365.25
df_join_all['age'] = df_join_all['age'].astype(int)

[ ]
current_date
datetime.datetime(2024, 10, 7, 9, 2, 8, 97101)

[ ]
# => Cái dataframe này dựa trên mã đơn hàng là ticket_id đã unique chứ không phải customer unique
# Nên muốn phân tích giới tính và độ tuổi phải tách customer_id unique ra kèm theo độ tuổi và giới tính
#lấy ra danh sách khách hàng cùng age,gender
df_cus = df_join_all.drop_duplicates(subset=['customer_id']) [['customer_id','dob', 'age', 'usergender' ]]

[ ]
df_cus.count()


[ ]
df_cus.head(2)
# => chúng ta có tuổi, giới tính muốn kiểm tra phân bổ ta sử dụng buổi đồ histogram


[ ]
# Phân bổ khách hàng theo độ tuổi
plt.figure(figsize=(8,4))
df_cus['age'].hist(bins = 30, color = 'cornflowerblue',grid = False)
plt.xlabel('age')
plt.ylabel('#customers')
plt.title('Age distribution')
plt.show()

vẽ biểu đồ histogram ra ta thấy người đặt vé xem phim có độ tuổi 20-40. Xu hướng giảm dần về 2 bên là nhóm số lượng đối tượng ít.
Nhưng có một nhóm người tăng đột biến ở độ tuổi hơn 50 và một vài người khoảng 80 tuổi và trên 100 tuổi ??
=> Liệu insight 2 có đúng như vậy ta có 3 nhóm male,female,not verify ta cùng phân tích độ tuổi theo nhóm giới tính để tìm hiểu thêm**


[ ]
# Phân bổ độ tuổi theo nhóm giới tính :
plt.figure(figsize=(8,4))

## data
male_age = df_cus[df_cus['usergender'] == 'Male']['age']
female_age = df_cus[df_cus['usergender'] == 'Female']['age']
unknown_age = df_cus[df_cus['usergender'] == 'Not verify']['age']

## plot
plt.hist(male_age, bins=30, alpha = 0.3, color = 'cornflowerblue', label = 'Male') #alpha: là độ đậm nhạt của màu sắc
plt.hist(female_age, bins=30, alpha = 0.3, color = 'salmon', label = 'Female')
plt.hist(unknown_age, bins=30, alpha = 0.3, color = 'limegreen', label = 'Not verify')

##edit
plt.title('Age distribution')
plt.xlabel('ages')
plt.ylabel('#customers')
plt.legend()
plt.show()


Xác định được độ tuổi khách hàng là từ 20 đến 40 tuổi ở Nam và Nữ (insight)
Nhưng có một nhóm người tăng đột biến ở độ tuổi hơn 50 và một vài người khoảng 80 tuổi và trên 100 tuổi ??(Câu hỏi phía trên)
=> Sau khi vẽ theo các nhóm giới tính ta nhận thấy nhóm tăng đột biến là nhóm chưa xác định được rõ giới tính, cần xác định số lượng là bao nhiêu, có thể họ không nhập đủ thông tin nên hệ thống tự mặc định là sinh năm 1970 là 54 tuổi


[ ]
#Đánh giá chi tiết nhóm not verify
df_gen = df_cus.groupby(by='usergender').agg(
    total=('customer_id','count')
).sort_values('total', ascending = False).reset_index()

[ ]
df_gen


[ ]
#Visualize
plt.pie(df_gen['total'],labels = df_gen['usergender'], colors = ['cornflowerblue', 'lightsteelblue','slategrey'],autopct = '%1.0f%%',startangle=90)
#'%1.0f%%': '.0 là làm tròn đến chữ số
#startangle là bắt đầu từ móc
plt.show()

Note Nhóm khách hàng chưa verify tài khoản chiếm hơn 11%. Dẫn đến 2 trường hợp:

Nếu họ nhập dob thì sẽ có data
Nếu họ không nhập thì hệ thống sẽ auto fill từ 1970 là 54 tuổi

[ ]
#Xác định lại 11% độ tuổi khoảng bao nhiêu và bao nhiêu người
df_cus[df_cus['usergender'] == 'Not verify'].groupby('age').agg(
    number = ('customer_id','count')
).reset_index().sort_values('number',ascending = False).head(10)

Age generation distribution
Xác định được độ tuổi khách hàng là từ 20 đến 40 tuổi ở Nam và Nữ (insight) từ giói hạn độ tuổi này chúng ta có thể phân loại theo nhóm thế hệ hay không?


[ ]
#Logic phân loại X,Y,Z, baby boomers(<1965)
#=> dựa vào năm sinh

[ ]
df_cus.head(2)


[ ]
df_cus['age_generation']=df_cus['dob'].apply(lambda x: 'baby boomers' if x.year < 1965 else 'gen X' if x.year < 1981 else 'gen Y' if x.year < 1997 else 'gen Z')
#hàm apply: a function along one of the axis of the DataFrame, default =0 (index 0)
#hàm apply kết hợp với hàm lambda có khả năng thay thế các vòng lặp for-vòng khó khăn.
#.map () , .apply () , .groupby () , .rolling () kết hợp với hàm lambda

[ ]
df_gen_group = (
    df_cus[df_cus['usergender'] != 'Not verify']
    .groupby('age_generation')
    .agg(total = ('customer_id','count'))
    .sort_values(by='total',ascending = False).reset_index()
)

[ ]
df_gen_group


[ ]
df_cus_not_verify = df_cus[df_cus['usergender'] != 'Not verify']

[ ]
#Kết hợp 2 biểu đồ cùng lúc
plt.figure(figsize = (13,4))

#plot 1
ax1 = plt.subplot(1,2,1)
#subplot(số dòng,có 2 cột,vị trí thứ nhất bên trái)
df_cus_not_verify['age'].hist(bins = 30,color='cornflowerblue',grid = False)
plt.xlabel('age')
plt.ylabel('#customers')
plt.title('Age distribution')

ax2 = plt.subplot(1,2,2)
#subplot(số dòng,có 2 cột,vị trí thứ nhất bên trái)
plt.pie(df_gen_group['total'],labels = df_gen_group['age_generation'], colors = ['cornflowerblue', 'lightsteelblue','slategrey','lightskyblue'],autopct = '%1.0f%%',startangle=90)
plt.show()

Tổng kết: Góc nhìn thứ nhất: khách hàng độ tuổi từ 20 đến 40 nam nữ không có sự khác biệt, nhóm chưa xác định chiếm 11% Góc nhìn thứ hai: xét theo nhóm thế hệ thì khách hàng chủ yếu tập trung và nhó Gen Y(59%) từ 29 tuổi đến 43 tuổi và Gen Z(36%) từ 28 tuổi trở về trước. Còn lại nhóm Gen X và Baby boomers chiếm thiểu số.

3.2 Time Series data - when did customers buy tickets?
Trend by month

[ ]
df_join_all.head(2)
# dữ liệu của chúng ta không có cột theo tháng chỉ có time (thời gian đặt vé)
# => nên từ cột time này sẽ chuyển nó về các column về tháng về ngày


[ ]
df_join_all['month'] = pd.to_datetime(df_join_all['time']).dt.month
df_join_all['name_day'] = pd.to_datetime(df_join_all['time']).dt.day_name()
df_join_all['hour'] = pd.to_datetime(df_join_all['time']).dt.hour
df_join_all['year_month'] = pd.to_datetime(df_join_all['time']).dt.strftime('%Y-%m')
#cột 'year_month' là format string

[ ]
#Thống kê theo tháng
df_time_month = (df_join_all.groupby('year_month')
                .agg(total_ticket = ('ticket_id','count'))
                .reset_index()#.sort_values(by='total',ascending = False)
)

[ ]
df_time_month.head(10)


[ ]
#Vẽ biểu đồ miền theo tháng
plt.figure(figsize=(13,4))
plt.fill_between(df_time_month['year_month'],df_time_month['total_ticket'],color = 'aqua',alpha = 0.2)
plt.title('#ticket by months')
plt.xticks(rotation = 90) #rotation: quay vòng
plt.show()

Giai đoạn 1-2020 đến 8-2020 và giai đoạn 5-2021 đến 11-2021 xu hướng mua vé xem phim giảm dần và thấp do ảnh hưởng bởi covid-19 nên không đi xem phim được
Ta để ý thấy chúng ta không có cột tháng 4-2020 và tháng 8,9-2021, chúng ta không có data tỏng 2 giai đoạn này
=> mình cần 1 bảng DIM thời gian theo tháng đầy đủ.


[ ]
#Tạo bảng DIM về thời gian để JOIN với data ticket và vẽ lại chart

#Xác định khoảng thời gian của data
start_date = '2019-01-01'
end_date = '2022-12-31'

#Tạo ra range thời gian từ 2 cột mốc start và end
date_range = pd.date_range(start = start_date,end = end_date,freq = 'MS')
    #freq là tần suất và MS viết tắt của MS:month start frequency là ngưng tại tháng bắt đầu

#Lấy ra list phần tử thời gian tương ứng
list_month = date_range.month
list_month_name = date_range.strftime('%B')
    #trong hàm strftime là chuỗi biểu diễn các giá trị thời gian '%A' viết tắt của trả về day_name,'%B' viết tắt của tên tháng trong năm
list_year = date_range.year
list_year_month = date_range.strftime('%Y-%m')

##Khởi tạo dataframe
dim_time=pd.DataFrame({
    'month_number':list_month,
    'month_name':list_month_name,
    'year':list_year,
    'year_month':list_year_month,
})

[ ]
dim_time


[ ]
#JOIN với bảng df_join_all để đủ data thời gian
df_time_month_dim = (
    pd.merge(dim_time,df_join_all,how='left',on='year_month')
    .groupby('year_month')
    .agg(total_ticket = ('ticket_id','count'))
    .reset_index()
)

[ ]
df_time_month_dim.replace(0,np.nan, inplace = True)

[ ]
df_time_month_dim


[ ]
# vẽ lại biểu đồ theo tháng
plt.figure(figsize=(13,4))
plt.fill_between(df_time_month_dim['year_month'],df_time_month_dim['total_ticket'],color = 'aqua',alpha = 0.2)
plt.title('#ticket by months')
plt.xticks(rotation = 90) #rotation: quay vòng
plt.show()

Nó vẫn có màu ở tháng 4/2020 và tháng 8,9/2021 tuy dữ liệu trên data là 0 vé đặt xem phim, vì số 0 vẫn là 1 con số nên muốn để trống chỗ này luôn thì đổi thành giá trị NULL

Trend by week days

[ ]
# Thống kê theo ngày trong tuần
df_week_day= (
    df_join_all
    .groupby('name_day')
    .agg(total_ticket =('ticket_id','count'))
    .reset_index()
)

[ ]
df_week_day


[ ]
#Vẽ biểu đồ theo ngày trong tuần
plt.figure(figsize=(13,4))
plt.fill_between(df_week_day['name_day'],df_week_day['total_ticket'],color = 'aqua',alpha = 0.2)
plt.title('#ticket by week days ')
plt.show()

Ta thấy chúng bị đảo ngược thứ tự, chúng ta muốn xem xu hướng thời gian từ thứ 2 đến CN


[ ]
# Sắp xếp thứ tự các ngày trong tuần

# Định nghĩa lại thứ tự các ngày trong tuần
week_order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']

#Sắp xếp theo thứ tự các ngày trong tuần
df_week_day['day_order']=pd.Categorical(df_week_day['name_day'],categories=week_order,ordered=True)
  #hàm categorical là hàm phân loại
df_week_day.sort_values(by='day_order',inplace = True)

[ ]
df_week_day



[ ]
#Vẽ lại biểu đồ theo ngày trong tuần
plt.figure(figsize=(13,4))
plt.fill_between(df_week_day['name_day'],df_week_day['total_ticket'],color = 'aqua',alpha = 0.2)
plt.title('#ticket by week days ')
plt.show()

Xu hướng người ta thường đi xem phim nhiều vào cuối tuần từ thứ 5 đến CN, và đỉnh điểm là thứ 7.

Trend by hour

[ ]
# Thống kê theo giờ
df_hour= (
    df_join_all
    .groupby('hour')
    .agg(total_ticket =('ticket_id','count'))
    .reset_index()
)

[ ]
df_hour


[ ]
#Vẽ lại biểu đồ theo giờ
plt.figure(figsize=(13,4))
plt.fill_between(df_hour['hour'],df_hour['total_ticket'],color = 'aqua',alpha = 0.2)
x_values = [i for i in range(0,24)] #biểu diễn đủ 1 đến 24 giờ
plt.xticks(x_values)
plt.title('#ticket by hours ')
plt.show()


[ ]
# Vẽ chung trên 1 frame
plt.figure(figsize=(13,8))

#Chart 1 trend by months
ax1 = plt.subplot(2,1,1)
#subplot(số dòng nghĩa là số ô chia figure ra 2 nghĩa là chia thành 2,có 2 cột,vị trí thứ nhất bên trái)
plt.fill_between(df_time_month_dim['year_month'],df_time_month_dim['total_ticket'],color = 'aqua',alpha = 0.2)
plt.title('#ticket by months')
plt.xticks(rotation = 90) #rotation: quay vòng

#Chart 2 trend by week days
ax2 = plt.subplot(2,2,3)
plt.fill_between(df_week_day['name_day'],df_week_day['total_ticket'],color = 'aqua',alpha = 0.2)
plt.xticks(rotation = 90)
plt.title('#ticket by week days ')

#Chart 3 trend by hour
ax3 = plt.subplot(2,2,4)
plt.fill_between(df_hour['hour'],df_hour['total_ticket'],color = 'aqua',alpha = 0.2)
x_values = [i for i in range(0,24)] #biểu diễn đủ 1 đến 24 giờ
plt.xticks(x_values)
plt.xticks(rotation = 90)
plt.title('#ticket by hours ')

#Điều chỉnh figure lại 1 lần nữa
plt.subplots_adjust(hspace = 0.5, top = 0.9) #hspace là khoảng cách giữa hàng trên và hàng dưới

3.3 Factors related to the customer's purchasing process
Payment platform

[ ]
df_join_all.head(2)


[ ]
df_platform = (
    df_join_all[df_join_all['platform'] != 'unknown']
    .groupby('platform')
    .agg(total_ticket = ('ticket_id','count'))
    .reset_index()
)

[ ]
df_platform


[ ]
# Có 2 cách một theo tỷ trọng vẽ biểu đồ tròn, hai là theo số lượng thì vẽ biểu đồ cột
# Biểu đồ cột ngang
plt.figure(figsize=(8,4))
plt.barh(df_platform['platform'],df_platform['total_ticket'],
         color = df_platform['platform'].replace({'mobile':'tomato','website':'lightskyblue'}))

for index,value in enumerate(df_platform['total_ticket']):
    plt.text(value,index,str(value))
# enumerate là function giúp chúng ta lấy ra từng cặp index với giá trị trong column, value có thể thay bằng i là tập hợp giá trị
plt.title('ticket by platform')


[ ]
#Biểu đồ tròn
plt.figure(figsize = (8,4))
plt.pie(df_platform['total_ticket'],labels = df_platform['platform'],colors =df_platform['platform'].replace({'mobile':'tomato','website':'lightskyblue'}) ,autopct = '%1.0f%%',startangle=90)
plt.title('ticket by platform')


[ ]
# Biểu diễn chung
plt.figure(figsize=(13,4))

# Biểu đồ cột ngang
ax1=plt.subplot(1,2,1)
plt.barh(df_platform['platform'],df_platform['total_ticket'],
         color = df_platform['platform'].replace({'mobile':'tomato','website':'lightskyblue'}))

for index,value in enumerate(df_platform['total_ticket']):
    plt.text(value,index,str(value))
# enumerate là function giúp chúng ta lấy ra từng cặp index với giá trị, value có thể thay bằng i là tập hợp giá trị
plt.title('ticket by platform')

#Biểu đồ tròn
ax2=plt.subplot(1,2,2)
plt.pie(df_platform['total_ticket'],labels = df_platform['platform'],colors =df_platform['platform'].replace({'mobile':'tomato','website':'lightskyblue'}) ,autopct = '%1.0f%%',startangle=90)
plt.title('ticket by platform')

plt.show()




[ ]
#Góc nhìn thứ 2: theo thời gian. Xu hướng thời gian thì website và mobile có thay đổi như thế nào
df_platform_time=(
    df_join_all[df_join_all['platform'] != 'unknown']
    .groupby(['year_month','platform'])
    .agg(total_ticket = ('ticket_id','count'))
    .reset_index()
)

[ ]
df_platform_time


[ ]
# Vẽ biểu đồ line chart
plt.figure(figsize=(13,4))
df_mobile_line = df_platform_time[df_platform_time['platform'] =='mobile']
plt.plot(df_mobile_line['year_month'],df_mobile_line['total_ticket'],label='mobile',marker='o',color = 'tomato',linewidth=2,markersize=4)

df_web_line = df_platform_time[df_platform_time['platform'] =='website']
plt.plot(df_web_line['year_month'],df_web_line['total_ticket'],label='website',marker='o',color = 'lightskyblue',linewidth=2,markersize=4)
plt.xticks(rotation = 90)
plt.legend() #nhập label= ở trên rồi chỉ cần gọi legend ra
plt.show() #function show chỉ show hình ảnh

Sau khi phân tích khách hàng thanh toán qua nền tảng nào ta thấy trong suốt 4 năm vừa rồi khách hàng đều thanh toán qua mobile rất là nhiều đạt 89% còn website chỉ 11%. Đỉnh điểm là năm 2022 khi khách hàng thanh toán qua mobile
Website chỉ mới có vào giao đoạn 2022 thôi trước đó chưa có, khách hàng chỉ mới bắt đầu thanh toán nhiều qua website từ năm 2022

[ ]
df_web_line

OS Version

[ ]
#Phân biệt OS version thành các nhóm: android_others,ios,unknown,browser
df_join_all['os_version']=df_join_all['model'].apply(lambda x: 'ios' if ('iPhone' in x or 'iPod' in x)
                                                      else 'browser' if 'browser' in x # 'browser' in x và x == 'browser'
                                                      else 'unknown' if ('devicemodel' in x or 'unknown' in x)
                                                      else 'android & other')
#.apply(lambda x: 'baby boomers' if x.year < 1965 else 'gen X' if x.year < 1981 else 'gen Y' if x.year < 1997 else 'gen Z')

[ ]
df_join_all['os_version'].unique()
array(['ios', 'browser', 'unknown', 'android & other'], dtype=object)

[ ]
# group by để thống kê
df_os = (df_join_all.groupby('os_version')
              .agg(total_ticket = ('ticket_id','count'))
              .sort_values(by='total_ticket',ascending = True).reset_index()
)

[ ]
df_os


[ ]
# Biểu diễn chung
plt.figure(figsize=(13,4))

# Biểu đồ cột ngang
ax1=plt.subplot(1,2,1)
plt.barh(df_os['os_version'],df_os['total_ticket'],
         color = df_os['os_version']
         .replace({ 'browser': 'lightsteelblue',  'android & other': 'lightskyblue', 'ios': 'cornflowerblue', 'unknown': 'steelblue'}))

for index,value in enumerate(df_os['total_ticket']):
    plt.text(value,index,str(value))
# enumerate là function giúp chúng ta lấy ra từng cặp index với giá trị, value có thể thay bằng i là tập hợp giá trị
plt.title('ticket by os')

#Biểu đồ tròn
ax2=plt.subplot(1,2,2)
plt.pie(df_os['total_ticket'],labels = df_os['os_version'],
        colors = df_os['os_version']
        .replace({ 'browser': 'lightsteelblue',  'android & other': 'lightskyblue', 'ios': 'cornflowerblue', 'unknown': 'steelblue'}),
        autopct = '%1.0f%%',startangle=90)
plt.title('ticket by os')

plt.show()


[ ]
#Theo thời gian
df_os_time = (
    df_join_all.groupby(['year_month','os_version'])
    .agg(total_ticket = ('ticket_id','count'))
    .sort_values(by='year_month',ascending = True).reset_index()
)

[ ]
df_os_time


[ ]
#Xử lý data dạng PIVOT để vẽ biểu đồ miền
df_os_time = (
    df_join_all
    .pivot_table(index = 'year_month', columns = 'os_version', aggfunc = 'count',values = 'ticket_id')
).reset_index()

[ ]
df_os_time


[ ]
#Vẽ biểu đồ miền THỜI GIAN
plt.figure(figsize=(13,4))

plt.fill_between(df_os_time['year_month'],df_os_time['ios'],color = 'cornflowerblue', alpha = 0.5,label = 'ios')
plt.fill_between(df_os_time['year_month'],df_os_time['android & other'],color = 'lightskyblue', alpha = 0.5,label = 'android & other')
plt.fill_between(df_os_time['year_month'],df_os_time['browser'],color = 'lightsteelblue', alpha = 0.5,label = 'browser')
plt.fill_between(df_os_time['year_month'],df_os_time['unknown'],color = 'steelblue', alpha = 0.5,label = 'unknown')

plt.title('#ticket of os version by time')
plt.xlabel('Month')
plt.ylabel('#ticket')
plt.legend(loc = 'upper left')
plt.xticks(rotation = 45)
plt.show()


[ ]
#biểu diễn chung 1 frame
plt.figure(figsize=(13,8))

#Vẽ biểu đồ miền THỜI GIAN
ax1=plt.subplot(2,1,1)
plt.fill_between(df_os_time['year_month'],df_os_time['ios'],color = 'yellow', alpha = 0.5,label = 'ios')
plt.fill_between(df_os_time['year_month'],df_os_time['android & other'],color = 'black', alpha = 0.5,label = 'android & other')
plt.fill_between(df_os_time['year_month'],df_os_time['browser'],color = 'red', alpha = 0.5,label = 'browser')
plt.fill_between(df_os_time['year_month'],df_os_time['unknown'],color = 'steelblue', alpha = 0.5,label = 'unknown')
plt.title('#ticket of os version by time')
plt.xlabel('Month')
plt.ylabel('#ticket')
plt.legend(loc = 'upper left')
plt.xticks(rotation = 45)

# Biểu đồ cột ngang
ax2=plt.subplot(2,2,3)
plt.barh(df_os['os_version'],df_os['total_ticket'],
         color = df_os['os_version']
         .replace({ 'browser': 'lightsteelblue',  'android & other': 'lightskyblue', 'ios': 'cornflowerblue', 'unknown': 'steelblue'}))
for index,value in enumerate(df_os['total_ticket']):
    plt.text(value,index,str(value))
# enumerate là function giúp chúng ta lấy ra từng cặp index với giá trị, value có thể thay bằng i là tập hợp giá trị
plt.title('ticket by os')

#Biểu đồ tròn
ax3=plt.subplot(2,2,4)
plt.pie(df_os['total_ticket'],labels = df_os['os_version'],
        colors = df_os['os_version']
        .replace({ 'browser': 'lightsteelblue',  'android & other': 'lightskyblue', 'ios': 'cornflowerblue', 'unknown': 'steelblue'}),
        autopct = '%1.0f%%',startangle=90)
plt.title('ticket by os')

#Điều chỉnh figure lại 1 lần nữa
plt.subplots_adjust(hspace = 0.5, top = 0.9)
plt.show()

Unknown lượt ticket_id đến tận 45% nhưng xuất hiện nhiều ở giai đoạn năm 2022 thôi, có thể năm 2022 đổi cách thức lưu trữ hoặc một lý do nào đó chúng ta mất 45% thông tin của khách hàng mua vé
Số lượng đặt vé trên ios nhiều hơn android và browser đến năm 2022 không thấy lượt mua vé trên android bị giảm đáng kể và lượt mua hàng trên browser tăng trong năm 2022
Payment method

[ ]
df_join_all.head(2)


[ ]
df_join_all['paying_method'].unique()
array(['money in app', 'bank account', 'debit card', 'credit card',
       'other'], dtype=object)

[ ]
df_method = (
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['paying_method'] != 'other')]
    .groupby('paying_method')
    .agg(total_ticket = ('ticket_id','count'))
    .reset_index()
)

[ ]
df_method


[ ]
df_method_time = (
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['paying_method'] != 'other')]
    .pivot_table(index = 'year_month',columns='paying_method',aggfunc = 'count',values='ticket_id')
).reset_index()

[ ]
df_method_time


[ ]
#biểu diễn chung 1 frame
plt.figure(figsize=(13,8))

#Vẽ biểu đồ miền THỜI GIAN
ax1=plt.subplot(2,1,1)
plt.fill_between(df_method_time['year_month'],df_method_time['bank account'],color = 'red', alpha = 0.5,label = 'bank account')
plt.fill_between(df_method_time['year_month'],df_method_time['credit card'],color = 'lightskyblue', alpha = 0.5,label = 'credit card')
plt.fill_between(df_method_time['year_month'],df_method_time['debit card'],color = 'lightsteelblue', alpha = 0.5,label = 'debit card')
plt.fill_between(df_method_time['year_month'],df_method_time['money in app'],color = 'steelblue', alpha = 0.5,label = 'money in app')
plt.title('#ticket of method by time')
plt.xlabel('Month')
plt.ylabel('#ticket')
plt.legend(loc = 'upper left')
plt.xticks(rotation = 45)

# Biểu đồ cột ngang
ax2=plt.subplot(2,2,3)
plt.barh(df_method['paying_method'],df_method['total_ticket'],
         color = df_method['paying_method']
         .replace({ 'debit card': 'lightsteelblue',  'credit card': 'lightskyblue', 'bank account': 'cornflowerblue', 'money in app': 'steelblue'}))
for index,value in enumerate(df_method['total_ticket']):
    plt.text(value,index,str(value))
# enumerate là function giúp chúng ta lấy ra từng cặp index với giá trị, value có thể thay bằng i là tập hợp giá trị
plt.title('ticket by method')

#Biểu đồ tròn
ax3=plt.subplot(2,2,4)
plt.pie(df_method['total_ticket'],labels = df_method['paying_method'],
        colors = df_method['paying_method']
        .replace({ 'debit card': 'lightsteelblue',  'credit card': 'lightskyblue', 'bank account': 'cornflowerblue', 'money in app': 'steelblue'}),
        autopct = '%1.0f%%',startangle=90)
plt.title('ticket by method')

#Điều chỉnh figure lại 1 lần nữa
plt.subplots_adjust(hspace = 0.5, top = 0.9)
plt.show()


[ ]
df_method_time = (
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['paying_method'] != 'other')]
    .pivot_table(index = 'year_month',columns='paying_method',aggfunc = 'count',values='ticket_id')
).reset_index()

# Biểu đồ miền lồng quá nhiều vào nhau khó thấy được sự trên lệnh tỷ trọng vào từng thời đểm
# Nên ta vẽ thêm biểu đồ miền 100% theo giai đoạn
df_method_time_pct = df_method_time.copy() #tạo ra bảng copy để dữ liệu bảng df_method_time không bị lỗi và vẽ ko bị lỗi
df_method_time_pct = df_method_time_pct.fillna(0) #để tránh lỗi những giá trị NA chuyển về giá trị 0 hết
df_method_time_pct['total'] = df_method_time_pct.iloc[:,1:].sum(axis=1)
#[:'nghĩa là lấy hết',vị trí từ 1 đến hết].sum(axis = 1 nghĩa là theo hàng ngang, =0 theo các cột)
# vị trí từ 1 đến hết, thứ tự các cột [index,0,1,2,..-1]
# hàm loc() dựa trên label trong dataframe còn hàm iloc() chủ yếu dựa trên vị trí số nguyên (từ 0 đến chiều dài-1 của trục)
# nghĩa là theo cột để tính toán

for i in df_method_time_pct.columns[1:5]: # nhớ đang cần truy xuất các cột để chạy for không dùng[] để truy xuất cột dùng hàm columns
  df_method_time_pct[i + '_pct'] = df_method_time_pct[i] / df_method_time_pct['total']

[ ]
df_method_time_pct.tail(10)
#lưu ý: tính toán mỗi lần chạy nó sẽ update lên nên ta chạy lại từ bảng df_method_time sẽ ko lỗi tính toán


[ ]
# vẽ biểu đồ miền 100%
plt.figure(figsize=(13,4))
plt.stackplot(df_method_time_pct['year_month'], df_method_time_pct["money in app_pct"],  df_method_time_pct['debit card_pct'], df_method_time_pct['credit card_pct'], df_method_time_pct['bank account_pct']
              , labels=['money in app', 'debit card', 'credit card', 'bank account'], colors=['royalblue', 'slategrey', 'lightsteelblue', 'cornflowerblue'], alpha=0.7)

plt.title('#ticket of method by time')
# plt.xlabel('Month')
plt.ylabel('#ticket')
plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))
plt.xticks(rotation=90)
plt.show()


[ ]
# biểu diễn chung 1 frame
plt.figure(figsize=(12, 8))

ax1 = plt.subplot(3,2,1)
plt.barh(
    df_method['paying_method'], df_method['total_ticket'],
    color = df_method['paying_method'].replace({ 'bank account': 'lightsteelblue',  'credit card': 'lightskyblue', 'debit card': 'cornflowerblue', 'money in app': 'steelblue'})
)

for index,value in enumerate(df_method['total_ticket']):
    plt.text(value,index,str(value))
plt.title('#ticket by method')

ax2 = plt.subplot(3,2,2)
plt.pie(df_method['total_ticket'], labels= df_method['paying_method'],
        colors=df_method['paying_method'].replace({ 'bank account': 'lightsteelblue',  'credit card': 'lightskyblue', 'debit card': 'cornflowerblue', 'money in app': 'steelblue'}),
        autopct='%1.0f%%',
        startangle=90)

ax3 = plt.subplot(3,1,2)
plt.fill_between(df_method_time['year_month'], df_method_time['bank account'], color='cornflowerblue', alpha=0.5, label='bank account')
plt.fill_between(df_method_time['year_month'], df_method_time['credit card'], color='lightskyblue', alpha=0.5, label='credit card')
plt.fill_between(df_method_time['year_month'], df_method_time['debit card'], color='lightsteelblue', alpha=0.5, label='debit')
plt.fill_between(df_method_time['year_month'], df_method_time['money in app'], color='steelblue', alpha=0.5, label='money in app')

plt.title('#ticket of method by time')
# plt.xlabel('Month')
plt.ylabel('#ticket')
plt.legend(loc='upper left')
plt.xticks(rotation=90)


ax4 = plt.subplot(3,1,3)
# vẽ biểu đồ miền 100%
plt.stackplot(df_method_time_pct['year_month'], df_method_time_pct["money in app_pct"],  df_method_time_pct['debit card_pct'], df_method_time_pct['credit card_pct'], df_method_time_pct['bank account_pct']
              , labels=['money in app', 'debit card', 'credit card', 'bank account'], colors=['royalblue', 'slategrey', 'lightsteelblue', 'cornflowerblue'], alpha=0.7)

plt.title('#ticket of method by time')
# plt.xlabel('Month')
plt.ylabel('#ticket_pct')
plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1)) # 1.15 cách ra figure 1.15
plt.xticks(rotation=90)

plt.subplots_adjust(hspace = 0.7, top = 0.9)
plt.show()

Promotion

[ ]
df_join_all['campaign_type'].unique()
array(['direct discount', 'unknown', 'voucher', 'reward point'],
      dtype=object)

[ ]
df_join_all['type'] = df_join_all['campaign_type'].apply(lambda x: 'non-promotion' if x == 'unknown' else 'promotion')

[ ]
df_join_all.head(2)


[ ]
df_type = (
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['paying_method'] != 'other')]
    .groupby('type')
    .agg(total_ticket = ('ticket_id','count'))
    .reset_index().sort_values(by = 'total_ticket',ascending = True)
)

[ ]
df_type


[ ]
#xử lý data dạng Pivot để vẽ biểu đồ miền của khuyến mãi và không khuyến mãi theo thời gian
df_type_time =(
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['paying_method'] != 'other')]
    .pivot_table(index = 'year_month',columns = 'type',aggfunc = 'count',values='ticket_id')
    .reset_index()
)
# tính pct
df_type_time_pct = df_type_time.copy()
df_type_time_pct = df_type_time_pct.fillna(0)
df_type_time_pct['total'] = df_type_time_pct.iloc[:,1:].sum(axis = 1)

for i in df_type_time_pct.columns[1:3]:
  df_type_time_pct[i + '_pct'] = df_type_time_pct[i] / df_type_time_pct['total']

[ ]
df_type_time_pct


[ ]
plt.figure(figsize=(12, 8))

ax1 = plt.subplot(3,2,1)
plt.barh(
    df_type['type'], df_type['total_ticket'],
    color = df_type['type'].replace({ 'non-promotion': 'lightskyblue', 'promotion': 'tomato'})
)

for index,value in enumerate(df_type['total_ticket']):
    plt.text(value,index,str(value))
plt.title('#ticket by promotion & non-promotion')

ax2 = plt.subplot(3,2,2)
plt.pie(df_type['total_ticket'], labels= df_type['type'],
        colors=df_type['type'].replace({'non-promotion': 'lightskyblue', 'promotion': 'tomato'}),
        autopct='%1.0f%%',
        startangle=90)
plt.title('#ticket by promotion & non-promotion')

ax3 = plt.subplot(3,1,2)
plt.plot(df_type_time['year_month'],df_type_time['non-promotion'],label = 'non-promotion',marker = 'o',color='lightskyblue',linewidth = 2,markersize = 4)
plt.plot(df_type_time['year_month'],df_type_time['promotion'],label = 'promotion',marker = 'o',color = 'tomato',linewidth = 2,markersize = 4)
plt.title('#ticket of promotion & non-promotion by time')
# plt.xlabel('Month')
plt.ylabel('#ticket')
plt.legend(loc='upper left')
plt.xticks(rotation=90)


ax4 = plt.subplot(3,1,3)
# vẽ biểu đồ miền 100%
plt.stackplot(df_type_time_pct['year_month'], df_type_time_pct['non-promotion_pct'],  df_type_time_pct['promotion_pct'],
               labels=['non-promotion_pct', 'promotion_pct'], colors=['lightskyblue', 'tomato'], alpha=0.7)

plt.title('#ticket of promotion & non-promotion_pct by time')
# plt.xlabel('Month')
plt.ylabel('#ticket_pct')
plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1)) # 1.15 cách ra figure 1.15
plt.xticks(rotation=90)

plt.subplots_adjust(hspace = 0.7, top = 0.9)
plt.show()

Which movies they watched?

[ ]
df_film_sum = (
    df_join_all[df_join_all['status_id'] == 1]
    .groupby('movie_name')
    .agg(total_ticket = ('ticket_id','count'),
         total_customer = ('customer_id','nunique'),
         revenue = ('final_price','sum'))
    .sort_values(by='total_ticket',ascending = False)
    .reset_index()
)

[ ]
df_film_sum.head(30)


[ ]
list_film = df_film_sum[df_film_sum['total_ticket'] > 1000]['movie_name'].unique()
list_selected_film = list(list_film)

[ ]
list_selected_film
['Doctor Strange In The Multiverse Of Madness',
 'Minions: The Rise Of Gru',
 'Avatar: The Way Of Water',
 'Thor: Love And Thunder',
 'Peninsula',
 'Black Panther 2: Wakanda Forever',
 'Black Adam',
 'Avengers: Endgame',
 "Dad I'm Sorry",
 'Love Destiny',
 'You And Trinh',
 'Fast & Furious Presents: Hobbs & Shaw',
 'Emergency Declaration',
 'Jurassic World Dominion',
 'Godzilla Vs. Kong',
 'Detective Conan: The Bride Of Halloween',
 'Joker',
 'Spider-Man: No Way Home',
 'Batman',
 'Blood Moon Party',
 'Fantastic Beasts: Secrets Of Dumbledore',
 'Top Gun: Maverick',
 'Naked Truth',
 "Doraemon: Nobita's Little Star Wars 2021",
 'One Piece Film: Red',
 'Confidential Assignment 2: International',
 'Extremely Easy Job',
 'Morbius',
 'Spider-Man Far From Home',
 'Maleficent',
 'Face Off: 48h',
 'Parasite']

[ ]
df_movie_time_pivot=(
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['movie_name'].isin(list_selected_film))]
    .pivot_table(index='year_month',columns='movie_name',aggfunc='count',values='ticket_id')
    .reset_index()
)

[ ]
df_movie_time_pivot


[ ]
#biểu đồ bar cột chồng lên nhau
df_movie_time_pivot.plot(x = 'year_month', kind='bar', stacked=True, figsize=(15, 6), width=0.8, alpha = 0.7)

# Set the title and labels
plt.title('Movie name trend')
# ax.set_xlabel('Month')
plt.ylabel('Number of Tickets')

# Add a legend
plt.legend(title='Movies', loc='upper right', bbox_to_anchor=(1.35, 1))

# Show the plot
plt.show()

3.4 Customer value dimension
Mục tiêu: phân tích các chỉ số về giá trị mà 1 khách hàng mang lại
Frequency: count, day,month
Monetary: total_money, total_discount
Success rate: number_success rate/ total
Promotion rate: number_promotion/total_success
Discount rate: sum discount/ sum money

[ ]
df_join_all.head(2)


[ ]
# Tính tất cả các chỉ số trên

# Tính các chỉ số cho những vé thanh toán thành công

def calculate_n_promotion(x):
  return (x == 'promotion').sum()

df_success_matric = (
    df_join_all[df_join_all['status_id'] == 1]
    .assign(date = pd.to_datetime(df_join_all['time']).dt.date)
# hàm assign là hàm khai báo 1 cột bằng 1 phép tính nào đó và cột này có có khi trong phép tính chứ không lưu cột này vào dataframe
    .groupby('customer_id')
    .agg(
        n_success = ('ticket_id','count'),
        s_money = ('original_price','sum'),
        s_discount = ('discount_value','sum'),
        n_days = ('date','nunique'),
        n_months = ('year_month','nunique'),
        n_promotions = ('type',calculate_n_promotion)
    )
    .reset_index()
)

[ ]
#chúng ta đã có bảng các chỉ số thanh toán về thành công của tất cả khách hàng
df_success_matric


[ ]
# tính các chỉ số về total và giao dịch lỗi của tất cả khách hàng

def calculate_n_failed(x):
  return(x != 1).sum() #status_id =1 là thành công

df_failed_matric = (
    df_join_all
    .groupby('customer_id')
    .agg(
        n_total = ('ticket_id','count'),
        n_failed = ('status_id',calculate_n_failed)
    )
    .reset_index()
)

[ ]
df_failed_matric


[ ]
#join 2 bảng này lại
df_customer_value = (
    pd.merge(df_failed_matric,df_success_matric,how = 'left',on='customer_id') #join theo bảng df_failed_matric vì đây là bảng đầy đủ có total
    .fillna(0)
)

[ ]
df_customer_value


[ ]
df_customer_value['success_rate']=df_customer_value['n_success']/df_customer_value['n_total']
df_customer_value['promotion_rate']=df_customer_value['n_promotions']/df_customer_value['n_success']
df_customer_value['discount_rate']=df_customer_value['s_discount']/df_customer_value['s_money']
# 3 chỉ số này tính trên đơn vị pct(%)

[ ]
df_customer_value.head(5)


[ ]
# Visualize tất cả các chỉ số bằng histogram:
df_customer_value.iloc[:,1:].hist(figsize=(12,9),grid = False,color = 'cornflowerblue',bins=20)
plt.show()

n_total: Hầu hết mọi người mua rất ít vé khoảng (1-2) nhưng có top những người mua rất nhiều vé -> cần check lại những người này
Có rất nhiều người bị fail 1 lần khoảng 100.000 người
Success rate: có khoảng 1 nhóm người SUCCESS_RATE=0% (10%-> kiểm tra lỗi gì?, mất khách hàng luôn)
promotion_rate: Có khoảng 60.000 KH chỉ mua vé khi mà promotion (khi mà promotion_rate = 100%)
n_promotion: Ta thấy có khoảng 60.000 chỉ có 1 đơn hàng khuyến mãi thôi
Design Thinking: Có thể 60.000 người này chỉ có 1 đơn hàng khuyến mãi chính là nhóm 60.000 mua vé promotion_rate = 100% và cũng là những người n_total thanh toán 1 lần rồi bỏ đi

Nhìn vào biểu đồ liên tục hỏi tại sao, kết hợp với các thông tin sản phẩm và kinh nghiệm thì chúng ta mới tìm ra được insight thực. This is Data Analysis. Tiếp tục đầo sâu các nghi vấn trên để ra được vấn đề (deep dive)

Frequency & anomaly behavior

[ ]
# Phân tích nghi vấn 1: Hầu hết mọi người mua rất ít vé khoảng (1-2) nhưng có top những người mua rất nhiều vé -> cần check lại những người này
df_customer_value['n_order_dis']=df_customer_value['n_success'].apply(lambda x: 'more than 10' if x >= 10 else str(x))
#dis viết tắt của distribution

[ ]
df_customer_value


[ ]
df_n_dis = df_customer_value.groupby('n_order_dis').agg(
    total_cus = ('customer_id','count')
).reset_index()

[ ]
df_n_dis


[ ]
plt.figure(figsize=(8,4))
plt.barh(df_n_dis['n_order_dis'], df_n_dis['total_cus'], color = 'aqua',alpha = 0.3)

for index,value in enumerate(df_n_dis['total_cus']):
  plt.text(value,index,str(value))
plt.title('#customer of each group')

Ta thấy:

Có tổng 11977 khách hàng, khách hàng mua 0 lần 13701 khoảng 10%
Khách hàng mua 1 lần rồi thôi 87921 khoảng 70%
Số còn lại mua trên 2 vé nhưng khoảng 5% khách hàng mua trên 3 vé
Có khoảng 74 người mua trên 10 vé ?? Tại sao

[ ]
df_customer_value.count()


[ ]
# Nếu họ mua dồn vào 1 lúc --> bất thường
# Nếu họ mua dàn trải --> loyal customer, bình thường

[ ]
df_customer_value.sort_values(by='n_success',ascending = False).head(20)


[ ]
list_customer_massive = list(df_customer_value[df_customer_value['n_success'] >= 30]['customer_id'].unique())

[ ]
list_customer_massive
[102948,
 103035,
 103347,
 108110,
 108162,
 108729,
 111644,
 114205,
 117140,
 117362,
 117475,
 118349,
 122962,
 131905,
 153124,
 153588,
 158089,
 168132,
 179471,
 222641,
 226527,
 226886]

[ ]
df_customer_massive_pivot = (
    df_join_all[(df_join_all['customer_id'].isin(list_customer_massive)) & (df_join_all['status_id'] == 1)]
    .pivot_table(index='year_month',columns = 'customer_id', aggfunc = 'count',values = 'ticket_id' )
    .reset_index()
)
# .pivot_table(index = 'year_month',columns = 'type',aggfunc = 'count',values='ticket_id')

[ ]
df_customer_massive_pivot


[ ]
#biểu đồ bar cột chồng lên nhau
df_customer_massive_pivot.plot(x = 'year_month', kind='bar', stacked=True, figsize=(15, 6), width=0.8, alpha = 0.7)

# Set the title and labels
plt.title('massive customer tred')
# ax.set_xlabel('Month')
plt.ylabel('Number of Tickets')

# Add a legend
plt.legend(title='customer_id', loc='upper right', bbox_to_anchor=(1.15, 1))

# Show the plot
plt.show()

Kết luận: Số lượng vé của nhóm khách hàng mua nhiều này mua dàn trải không có gì bất thường. Không có hiện tượng spam vé mua đi bán lại

Masive Promotion

[ ]
# Coi lại phân bổ promotion coi mỗi người là bao nhiêu

[ ]
df_customer_value['n_promo_dis']= df_customer_value['n_promotions'].apply(lambda x: 'more than 10' if x >= 10 else str(x))

[ ]
df_customer_value.head(2)


[ ]
# đếm số người theo số lần nhận khuyến mãi
df_promo_dis = (
    df_customer_value.groupby('n_promo_dis')
    .agg(total_cus = ('customer_id','count'))
    .reset_index()
)

[ ]
df_promo_dis


[ ]
# Vẽ biểu đồ xem phân bố khách hàng nhận khuyến mãi
plt.figure(figsize=(8,4))
plt.barh(df_promo_dis['n_promo_dis'],df_promo_dis['total_cus'],color= 'aqua',alpha= 0.5)
for index,value in enumerate(df_promo_dis['total_cus']):
  plt.text(value,index,str(value))
plt.title('#customer of each group')

Ta có khoảng 70% số khách hàng có sử dụng khuyến mãi. Trong 70% đó ta có 90% người sử dụng khuyến mãi 1 lần

Khách hàng đến 1 lần rồi thôi
Các chương trình promotion chỉ dùng cho 1 người dùng 1 lần (new customer)??? => verify lại với team product, MKT

[ ]
#Vậy loại khuyến mãi mà khách hàng đang dùng là gì

[ ]
df_join_all.head(2)


[ ]
#Đánh giá mã khuyến mãi mà khách hàng dùng
df_type_group = (
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['type'] == 'promotion')]
    .groupby('campaign_type')
    .agg(total_ticket=('ticket_id','count'))
    .reset_index()
)

[ ]
df_type_group
## Ta thấy trong nhóm nhận khuyến mãi thì có khoảng 90% số vé là loại khuyến mãi direct discount,
## nhưng ta vẫn chưa xác định được tỏng mỗi nhóm khách KM1 lần,KM2 lần,... sử dụng loại hình khuyến mãi nào và tỷ trọng mỗi nhóm là bao nhiêu %
## cần phân tích sâu từng nhóm


[ ]
## Tính tỷ lệ loại khuyến mãi chi tiết cho từng nhóm khách hàng(nhóm 1KM,nhóm 2KM,...)

[ ]
## Tính mỗi người khách hàng có bao nhiêu promotion
df_n_success=(
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['type'] == 'promotion')]
    .groupby('customer_id')
    .agg(n_promotions = ('ticket_id','count'))
    .reset_index()
)

[ ]
df_n_success.count()


[ ]
df_n_pivot =(
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['type'] == 'promotion')]
    .pivot_table(index = 'customer_id',columns='campaign_type',aggfunc = 'count',values='ticket_id')
    .reset_index()
)

[ ]
df_n_pivot


[ ]
df_n_join =(
    pd.merge(df_n_success,df_n_pivot,how='inner',on='customer_id')
    .groupby('n_promotions')
    .agg(n_cus=('customer_id','count'),
         n_voucher=('voucher','sum'),
         n_direct_discount=('direct discount','sum'),
         n_reward_point=('reward point','sum')
          )
    .reset_index()
)

[ ]
df_n_join


[ ]
df_n_join['total']=df_n_join.iloc[:,2:].sum(axis=1)

[ ]
for i in df_n_join.columns[2:5]:
  df_n_join[i + '_pct']=df_n_join[i]/df_n_join['total']


[ ]
df_n_join


[ ]
format_dict={'total':'{:.0f}','n_voucher_pct':'{:.0%}','n_direct_discount_pct':'{:.0%}','n_reward_point_pct':'{:.0%}'}

[ ]
#Tô màu (heat map) cho table
(
    df_n_join
    .drop(columns=['n_voucher','n_direct_discount','n_reward_point'])
    .style
    .format(format_dict)
    .background_gradient(subset=['n_voucher_pct','n_direct_discount_pct','n_reward_point_pct'],cmap='PuBu')
    .background_gradient(subset=['total'],cmap='YlGn')
)

Tất cả các nhóm khách hàng theo số lượng promotion đều sử dụng loại khuyến mãi direct_discount rất nhiều (tỷ lệ có thay đổi một ít thôi). Nên là direct discount vẫn là best option của chúng ta.

Họ sử dụng khuyến mãi rồi họ có quay trở lại hay không?? Đánh giá thêm về Retention của KH

3.5 Customer Retention - Cohort Analysis

[ ]
# Dựa vào lần đầu chuyển đổi khách hàng: lần đầu tiên thanh toán, mua hàng, cài app,..

[ ]
from operator import attrgetter # attrgetter return an attribute from an object
import matplotlib.colors as mcolors
import seaborn as sns

[ ]
#Bước 1: Tính toán các thông tin: Cohort (first_month),current month, subsequent month
df_selected_time = df_join_all[(df_join_all['time'] < '2020-01-01') & (df_join_all['status_id'] == 1)]
#Tạo cột first_month
df_selected_time['first_month'] = df_selected_time.groupby('customer_id')['time'].transform('min').dt.to_period('M')
# transform() method allows you to execute a function for each value of the DataFrame.
# period() method represents a period of time. Ý nghĩa của code trên period('M') là trả về tháng hiện tại của khoảng thời gian
# ý nghĩa của code trên là groupby theo từng KH lấy cột time chọn ra min_time(lầy đầu) của từng KH

df_selected_time['current_month'] = df_selected_time['time'].dt.to_period('M')
# giống ý nghĩa và cách khác như cột year_month

df_selected_time['subsequent_month'] = (df_selected_time['current_month'] - df_selected_time['first_month']).apply(attrgetter('n'))
#Subsequent: khoảng cách của những giao dịch hiện tại với giao dịch đầu tiên
<ipython-input-397-f6becddc947a>:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_selected_time['first_month'] = df_selected_time.groupby('customer_id')['time'].transform('min').dt.to_period('M')
<ipython-input-397-f6becddc947a>:9: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_selected_time['current_month'] = df_selected_time['time'].dt.to_period('M')
<ipython-input-397-f6becddc947a>:12: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_selected_time['subsequent_month'] = (df_selected_time['current_month'] - df_selected_time['first_month']).apply(attrgetter('n'))

[ ]
df_selected_time.head(5)


[ ]
# Bước 2: Groupby theo Cohort
df_cohort = (
    df_selected_time
    .groupby(['first_month','current_month','subsequent_month'])
    .agg(n_customers = ('customer_id','nunique'))
    .reset_index(drop = False)
)

[ ]
df_cohort.head(10) #pivot kết quả này


[ ]
df_cohort_pivot = (
    df_cohort
    .pivot_table(index='first_month',columns='subsequent_month',values='n_customers')
)

[ ]
df_cohort_pivot # bước tiếp theo chuyển kết quả về dạng % và visual table


[ ]
# chuyển về %
cohort_size = df_cohort_pivot.iloc[:,0] #xác định mẫu
retention_matrix = df_cohort_pivot.divide(cohort_size,axis = 0)
# divide() struction: get Floating division(chia) of dataframe and other_element-wise (theo từng phần tử)
# ý nghĩa code: retention_matrix = df_cohort_pivot(từng cột,hàng tương ứng) chia cho cohort_size(mẫu) theo hàng ngang

[ ]
cohort_size


[ ]
retention_matrix


[ ]
# Vẽ biểu đồ cohort
with sns.axes_style("white"): #sns seaborn library là một thư viện để visualizations giống với matplotlib
# lấy ra thư viện seaborn axes_style('white') nghĩa là lấy cái nền màu trắng
    fig, ax = plt.subplots(1, 2, figsize=(12, 8), sharey=True, gridspec_kw={'width_ratios': [1, 11]})
# khai báo subplots 1 dòng 2 cột là có 2 biểu đồ, sharey=True là dùng chung trục y
# gridspec_kw={'width_ratios': [1, 11]} là khai báo tỷ lệ cho biểu đồ, 1 là cho biểu đồ thứ 1, 11 là cho biểu đồ thứ 2 tổng là 12(figsize)

    # retention matrix (biểu đồ thứ nhất) heatmap là biểu đồ nhiệt
    sns.heatmap(retention_matrix,
                mask=retention_matrix.isnull(), #mask là che lại, nghĩa là chỗ nào NULL thì không cho hiển thị ra
                annot=True, #annot=True nghĩa là show ra values của từng ô
                fmt='.0%', # fmt là format nó về chữ số thập phân thứ 0
                cmap='YlGnBu',#cmap là bảng màu
                ax=ax[1]) #lấy trục x là biểu đồ thứ nhất
    ax[1].set_title('Monthly Cohorts: User Retention 2019', fontsize=16)
    ax[1].set(xlabel='subsequent months',
              ylabel='')

    # cohort size (biểu đồ thứ hai)
    cohort_size_df = pd.DataFrame(cohort_size).rename(columns={0: 'original customers'}) #rename đổi tên cột
    white_cmap = mcolors.ListedColormap(['white']) #lấy màu trắng
    sns.heatmap(cohort_size_df,
                annot=True,
                cbar=False,
                fmt='g',
                cmap=white_cmap,
                alpha=0.5,
                ax=ax[0])

    fig.tight_layout()


[ ]
#chạy tương tự năm 2022 (BT)

[ ]
df_selected_time = df_join_all[(df_join_all['time'] > '2022-01-01') & (df_join_all['status_id'] == 1)]
df_selected_time['first_month'] = df_selected_time.groupby('customer_id')['time'].transform('min').dt.to_period('M')
df_selected_time['current_month']=df_selected_time['time'].dt.to_period('M')
# df_join_all['year_month'] = pd.to_datetime(df_join_all['time']).dt.strftime('%Y-%m')
df_selected_time['subsequent_month'] = (df_selected_time['current_month'] - df_selected_time['first_month']).apply(attrgetter('n'))
<ipython-input-408-a274f17471e6>:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_selected_time['first_month'] = df_selected_time.groupby('customer_id')['time'].transform('min').dt.to_period('M')
<ipython-input-408-a274f17471e6>:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_selected_time['current_month']=df_selected_time['time'].dt.to_period('M')
<ipython-input-408-a274f17471e6>:5: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_selected_time['subsequent_month'] = (df_selected_time['current_month'] - df_selected_time['first_month']).apply(attrgetter('n'))

[ ]
df_selected_time.head(5)


[ ]
# Bước 2: Groupby theo Cohort
df_cohort = (
    df_selected_time
    .groupby(['first_month','current_month','subsequent_month'])
    .agg(n_customers = ('customer_id','nunique'))
    .reset_index(drop= False)
)


[ ]
df_cohort.head(10) #pivot df_cohort


[ ]
df_cohort_pivot = (
    df_cohort
    .pivot_table(index='first_month',columns='subsequent_month',values='n_customers')
)

[ ]
df_cohort_pivot


[ ]
#tính % cho các tháng
cohort_size=df_cohort_pivot.iloc[:,0] #xác định mẫu
retention_matrix = df_cohort_pivot.divide(cohort_size,axis = 0)


[ ]
cohort_size


[ ]
retention_matrix


[ ]

# Vẽ biểu đồ cohort
with sns.axes_style("white"): #sns seaborn library là một thư viện để visualizations giống với matplotlib
# lấy ra thư viện seaborn axes_style('white') nghĩa là lấy cái nền màu trắng
    fig, ax = plt.subplots(1,2,figsize=(12,8),sharey=True,gridspec_kw={'width_ratios': [1,11]}) #width_ratios: tỷ lệ chiều rộng
# khai báo subplots 1 dòng 2 cột là có 2 biểu đồ, sharey=True là dùng chung trục y
# gridspec_kw={'width_ratios': [1, 11]} là khai báo tỷ lệ cho biểu đồ, 1 là cho biểu đồ thứ 1, 11 là cho biểu đồ thứ 2 tổng là 12(figsize)

    # retention matrix (biểu đồ thứ nhất) heatmap là biểu đồ nhiệt
    sns.heatmap(retention_matrix,
                mask=retention_matrix.isnull(), #mask là che lại, nghĩa là chỗ nào NULL thì không cho hiển thị ra
                annot=True, #annot=True nghĩa là show ra values của từng ô #annot: nghĩa là ghi chú
                fmt='.0%', # fmt là format nó về chữ số thập phân thứ 0
                cmap='YlGnBu',#cmap là bảng màu
                ax=ax[1]) #lấy trục x là biểu đồ thứ nhất
    ax[1].set_title('Monthly Cohorts: User Retention 2022', fontsize=16)
    ax[1].set(xlabel='subsequent months',
              ylabel='')

    # cohort size (biểu đồ thứ hai)
    cohort_size_df = pd.DataFrame(cohort_size).rename(columns={0: 'original customers'}) #rename đổi tên cột
    white_cmap = mcolors.ListedColormap(['white']) #lấy màu trắng
    sns.heatmap(cohort_size_df,
                annot=True,
                cbar=False,
                fmt='g',
                cmap=white_cmap,
                alpha=0.5,
                ax=ax[0])

    fig.tight_layout()


Retention 2019 và 2022 không có nhiều sự thay đổi, do thị trường phim mới hồi phục nên chưa có nhiều thời gian để công ty cải thiện
Hoặc là công ty chỉ mới đầu tư vào khách hàng mới thôi chưa có chính sách giữ chân khách hàng cũ
Retention thấp mặc dù tỷ lệ hưởng khuyến mãi promotion 60-65%?
Compare: Retention of promotion customers & organic customers

[ ]
# By payment method
df_pie_promo = (
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['time'] > '2022-01-01')]
    .groupby('type')
    .agg(total_ticket=('customer_id','nunique'))
    .sort_values(by='total_ticket',ascending=True).reset_index()
)

[ ]
df_pie_promo


[ ]
#pie
plt.figure(figsize=(8,4))
plt.pie(df_pie_promo['total_ticket'],
        labels=df_pie_promo['type'],
        autopct='%1.0f%%',
        colors=df_pie_promo['type'].replace({'non-promotion':'skyblue','promotion':'tomato'}),
        startangle=90
        )
plt.title('Percent of type')
plt.show()


[ ]
# Phân biệt nhóm promotion và nhóm organic: dựa vào vé đầu tiên (first_order) có khuyến mãi hay không
# => để làm việc này ta cần đánh STT đơn hàng của từng người

[ ]
df_data_check=(
    df_join_all[(df_join_all['status_id'] == 1) & (df_join_all['time'] > '2022-01-01')] [['customer_id','ticket_id','time','type']]
    .sort_values(by=['customer_id','time'])
)

[ ]
df_data_check


[ ]
# Đánh số thứ tự các vé của khách hàng
df_data_check['row_number'] = df_data_check.groupby('customer_id').cumcount() + 1

[ ]
# Số khách hàng có first_payment là promotion
df_data_check[(df_data_check['type'] == 'promotion') & (df_data_check['row_number'] == 1)] ['customer_id'].nunique()
46189

[ ]
46189/47507
0.9722567200623066

[ ]
# chúng ta có 97% khách hàng đến từ promotion trong nhóm khách hàng có tham gia promotion
# => Retention là bao nhiêu

[ ]
#groupby tạo ra df chỉ gồm các khách hàng promotion
df_first_promo_list = df_data_check[(df_data_check['type'] == 'promotion') & (df_data_check['row_number'] == 1)] ['customer_id']
df_first_promo_list.drop_duplicates(inplace=True)
df_first_promo_check = pd.merge(df_data_check,df_first_promo_list,how='inner',on='customer_id')
<ipython-input-437-5abe3db8197b>:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_first_promo_list.drop_duplicates(inplace=True)

[ ]
#tính xem trong nhóm KH promotion có bao nhiêu quay lại
(
    df_first_promo_check[ (df_first_promo_check['row_number'] == 2) ] ['customer_id'].nunique()
/
    df_first_promo_check['customer_id'].nunique()
)
0.1308969668102795

[ ]
# 13% KH quay lại kể từ lần đầu tham gia promotion (tỷ lệ chuyển đổi, giữ chân = 13%)

# => nhóm organic có khác biệt không ??

[ ]
list_first_non_promo = df_data_check[(df_data_check['type'] == 'non-promotion') & (df_data_check['row_number'] == 1)] ['customer_id']
list_first_non_promo.drop_duplicates(inplace=True)
df_first_non_promo_check = pd.merge(df_data_check,list_first_non_promo,how='inner',on='customer_id')
(
    df_first_non_promo_check[df_first_non_promo_check['row_number'] == 2]['customer_id'].nunique()
/
    df_first_non_promo_check['customer_id'].nunique()
)
<ipython-input-443-d436467d2d46>:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  list_first_non_promo.drop_duplicates(inplace=True)
0.12195316551641601

[ ]
# Nhóm KH first_time có lần đầu là organic => tỷ lệ giữ chân = 12%
Chỉ có 13% khách hàng quay lại với nhóm lần đầu promotion và 12% khách hàng quay lại với nhóm non-promotion. Kết luận: không có sự khác biệt ở tỷ lệ giữ chân khách hàng ở cả 2 nhóm.
=> Công ty đang chú trọng vào NEW CUSTOMERS nhưng chưa đẩy mạnh việc giữ chân và duy trì lượng khách hàng cũ.

3.6 Payment success rate
Overview

[ ]
# Kiểm tra lại success rate toàn thời gian

[ ]
def calculate_n_success(x):
  return(x==1).sum()

df_sr = (
    df_join_all
    .groupby('year_month')
    .agg(
        n_ords= ('ticket_id','count'), #total_ticket
        n_success = ('status_id',calculate_n_success)) #success_ticket
    .assign(success_rate= lambda x: (x['n_success'] / x['n_ords']) * 100) #tạo thêm 1 columns tính SR
    .reset_index()
)

[ ]
df_sr.head(2)


[ ]
# Vẽ biểu đồ cột và đường
from matplotlib.ticker import PercentFormatter # import định djang phần trăm trong matplotlib

fig,ax1=plt.subplots(figsize=(15,4))

ax1.bar(df_sr['year_month'],df_sr['n_ords'],color='cornflowerblue')
plt.ylabel('#tickets',fontsize=11)
plt.xticks(rotation='vertical') # giống =90

ax2=ax1.twinx() # nó sẽ hiểu lấy trục y đặt bên tay phải
ax2.plot(df_sr['year_month'],df_sr['success_rate'],color="tomato", marker="o", ms=3) #ms(markersize) là kích thước của marker
ax2.yaxis.set_major_formatter(PercentFormatter())

plt.ylabel('success rate',fontsize=11)
plt.title('Payment success rate by months', fontsize=14)

plt.show()

Overview: Ta thấy hầu hết tỷ lệ giao dịch thành công của ta từ 60% trở lên. Có những thời điểm đạt 100%. Trong năm 2022, tỷ lệ giao dịch thành công giao động từ 75% đến 93%.

=> Tổng quan là vậy giờ ta đào sâu vào các giao dịch không thành công

Error trend

[ ]
df_join_all.head(2)
# Ta thấy có cột description mô tả giao dịch đó và cột error_group nhóm lỗi của các giao dịch
# => Vậy ta groupby theo error_group để kiểm tra xe từng lỗi gì


[ ]
# phân bố nhóm lỗi:
df_error_group = (
   df_join_all[df_join_all['description'] != 'Order successful']
   .groupby(['year_month','error_group'])
   .agg(n_ords = ('ticket_id','count'))
   .sort_values(by='year_month',ascending=True)
   .reset_index()
)

[ ]
df_error_group.head(5)


[ ]
df_error_group['error_group'].unique()
array(['customer', 'external', 'internal'], dtype=object)

[ ]
#phân bố nhóm lỗi
#Thông thường vẽ line char có nhiều line ta nên khai báo nhóm màu cho từng line trước
error_color_pairs=[('external','tomato'),('customer','skyblue'),('internal','green')]

plt.figure(figsize=(15,4))

for error,color in error_color_pairs:
  df_error_line=df_error_group[df_error_group['error_group'] == error]
  plt.plot(df_error_line['year_month'],df_error_line['n_ords'], label=error, marker='o', color=color, linewidth=2, ms= 3)
#chạy vòng lặp for cho 3 line thay vì viết code lần lượt 3 line

plt.title('total ticket of error group by months')
plt.xlabel('month')
plt.ylabel('#tickets')
plt.legend(loc = 'upper right',bbox_to_anchor=(1.15,1))
plt.xticks(rotation=90)

plt.show()

Ta thấy nhóm lỗi customer lúc nào cũng có.
Nhóm lỗi internal thì giao động ở mức thấp.
Nhóm lỗi external là nhóm lỗi giao động cao nhất và đặc biệt như kết luận tổng quan trên năm 2022 có xu hướng giao dịch thành công tăng cao và nhóm lỗi external cũng tăng vọt vào thời điểm đó.
=> Vậy tìm hiểu thêm tại sao nhóm lỗi external lại tăng cao như vậy


[ ]
# Nhóm lỗi external tăng đột biến trong năm 2022 ??

[ ]
#Phân bố mã lỗi
df_error = (
   df_join_all[df_join_all['description'] != 'Order successful']
   .groupby(['year_month','description'])
   .agg(n_ords = ('ticket_id','count'))
   .sort_values(by='year_month',ascending=True)
   .reset_index()
)

[ ]
df_error.head(10)


[ ]
df_error['description'].unique() # có tổng 7 mã lỗi
array(['Insufficient funds in customer account. Please add more funds and try the transaction again.',
       'No response from your bank',
       'Password locked due to multiple incorrect attempts. Choose Forgot Password to unlock.',
       'Payment failed from bank', 'Payment overdue',
       'Transaction temporarily limited',
       'Need verify your account to continue'], dtype=object)

[ ]
#phân bố mã lỗi
#Thông thường vẽ line char có nhiều line ta nên khai báo nhóm màu cho từng line trước
error_color_pairs=[('Payment failed from bank','gray'),
 ('Insufficient funds in customer account. Please add more funds and try the transaction again.','tomato'),
  ('No response from your bank','skyblue'),('Password locked due to multiple incorrect attempts. Choose Forgot Password to unlock.','green'),
   ('Payment overdue','purple'),('Transaction temporarily limited','blue'),('Need verify your account to continue','peru')]

plt.figure(figsize=(15,4))

for error,color in error_color_pairs:
  df_error_line=df_error[df_error['description'] == error]
  plt.plot(df_error_line['year_month'],df_error_line['n_ords'], label=error, marker='o', color=color, linewidth=2, ms= 3)
#chạy vòng lặp for cho 7 line thay vì viết code lần lượt 7 line

plt.title('total ticket of error group by months')
plt.xlabel('month')
plt.ylabel('#tickets')
plt.legend(loc = 'upper right',bbox_to_anchor=(1.15,1))
plt.xticks(rotation=90)

plt.show()

=> Lỗi mà năm 2022 mắc nhiều nhất: payment failed from bank và need verify your account to continue ( lỗi do 1 bên thứ 3 external) và họ ngừng giao dịch luôn, những lỗi do bên thứ 3 này khó mà kiểm soát được

SR=0% WHY and HOW ?

[ ]
df_customer_value.head(5)


[ ]
list_sr_0=list(df_customer_value[df_customer_value['success_rate'] < 0.1]['customer_id'].unique())

[ ]
df_customer_value[df_customer_value['success_rate'] < 0.1]['customer_id'].nunique() # 13701 người RS=0%
13701

[ ]
def calculate_n_promotion(x):
  return(x=='promotion').sum()

df_sr_0_metric=(
    df_join_all[df_join_all['customer_id'].isin(list_sr_0)]
    .groupby('customer_id')
    .agg(n_orders=('ticket_id','count'),
         s_money=('original_price','sum'),
         s_discount=('discount_value','sum'),
         n_promotions=('type',calculate_n_promotion)
         )
    .reset_index()
)

[ ]
df_sr_0_metric['promotion_rate'] = df_sr_0_metric['n_promotions']/df_sr_0_metric['n_orders']
df_sr_0_metric['discount_rate'] = df_sr_0_metric['s_discount']/df_sr_0_metric['s_money']

[ ]
df_sr_0_metric.iloc[:,1:].hist(figsize=(13,8), grid=False, color='skyblue', bins=20)
plt.show()

Kết luận:

nhóm người RS=0% họ không thử lại thất bại họ đi luôn (13701 người xem n_orders)
nhóm người này có khoảng hơn 8000 người hưởng khuyến mãi 1 lần

[ ]
# Họ bị lỗi gì vậy mà fail 1 lần rồi stop luôn. Họ không retry?

[ ]
#Detail error
#Phân tích nhóm lỗi

df_error_0 =(
    df_join_all[(df_join_all['status_id'] != 1) & (df_join_all['customer_id'].isin(list_sr_0))]
    .groupby(['year_month','description'])
    .agg(
        n_ords=('ticket_id','count'))
    .sort_values(by='year_month',ascending=True)
    .reset_index()
)

[ ]
df_error_0.head(10)


[ ]
#phân bố mã lỗi
#Thông thường vẽ line char có nhiều line ta nên khai báo nhóm màu cho từng line trước
error_color_pairs=[('Payment failed from bank','gray'),
 ('Insufficient funds in customer account. Please add more funds and try the transaction again.','tomato'),
  ('No response from your bank','skyblue'),('Password locked due to multiple incorrect attempts. Choose Forgot Password to unlock.','green'),
   ('Payment overdue','purple'),('Transaction temporarily limited','blue'),('Need verify your account to continue','peru')]

plt.figure(figsize=(15,4))

for error,color in error_color_pairs:
  df_error_line=df_error_0[df_error_0['description'] == error]
  plt.plot(df_error_line['year_month'],df_error_line['n_ords'], label=error, marker='o', color=color, linewidth=2, ms= 3)
#chạy vòng lặp for cho 7 line thay vì viết code lần lượt 7 line

plt.title('total ticket of error group by months')
plt.xlabel('month')
plt.ylabel('#tickets')
plt.legend(loc = 'upper right',bbox_to_anchor=(1.15,1))
plt.xticks(rotation=90)

plt.show()

Nhóm bị lỗi này cũng gần như (giống) nhóm bị lỗi của toàn bộ KH (nhìn lại line char phía trên)
Lý do họ lỗi và stop là do:
Payment failed from bank
Need verify your account to continue
Colab paid products - Cancel contracts here
